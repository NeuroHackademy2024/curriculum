{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ordv4cRyTpbo"
   },
   "source": [
    "**Krakencoder usage example**\n",
    "\n",
    "This notebook provides an example of how to load connectome data and apply a pretrained Krakencoder model to that data.\n",
    "\n",
    "The process is as follows:\n",
    "1.   Load model\n",
    "2.   Load new data and do mild domain adaptation (map input data mean to training data mean)\n",
    "3.   Transform each input data flavor into 128-dimensional latent space\n",
    "4.   Average latent space across all types (\"fusion\")\n",
    "  * Note: this might be used for prediction, clustering, etc.\n",
    "5.   Transform \"fusion\" averaged latent vectors to output connectomes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQv3DFzCDVUP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from krakencoder.model import Krakencoder\n",
    "from krakencoder.adaptermodel import KrakenAdapter\n",
    "from krakencoder.utils import square2tri, tri2square, numpyvar\n",
    "from krakencoder.data import generate_adapt_transformer, load_transformers_from_file\n",
    "from krakencoder.fetch import fetch_model_data\n",
    "from scipy.io import loadmat, savemat\n",
    "import os\n",
    "import humanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YntFPS-vGLKS",
    "outputId": "d7f256a5-0c53-4ad3-bb05-86e80ce27036"
   },
   "outputs": [],
   "source": [
    "# load model checkpoint and precomputed PCA transforms\n",
    "# The first time these are used, they are downloaded to package_dir/model_data (~1.3GB)\n",
    "# To use an alternate storage location, you can set the KRAKENCODER_DATA environment variable\n",
    "checkpoint_file=fetch_model_data('kraken_chkpt_SCFC_fs86+shen268+coco439_pc256_225paths_latent128_20240413_ep002000.pt', \n",
    "                                 data_folder=\"/home/jovyan/shared/krakencoder/model_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YntFPS-vGLKS",
    "outputId": "d7f256a5-0c53-4ad3-bb05-86e80ce27036"
   },
   "outputs": [],
   "source": [
    "ioxfm_file_list=fetch_model_data(['kraken_ioxfm_SCFC_fs86_pc256_710train.npy',\n",
    "                                  'kraken_ioxfm_SCFC_shen268_pc256_710train.npy',\n",
    "                                  'kraken_ioxfm_SCFC_coco439_pc256_710train.npy'], \n",
    "                                  data_folder=\"/home/jovyan/shared/krakencoder/model_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YntFPS-vGLKS",
    "outputId": "d7f256a5-0c53-4ad3-bb05-86e80ce27036"
   },
   "outputs": [],
   "source": [
    "inner_net, checkpoint_info = Krakencoder.load_checkpoint(checkpoint_file, eval_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YntFPS-vGLKS",
    "outputId": "d7f256a5-0c53-4ad3-bb05-86e80ce27036"
   },
   "outputs": [],
   "source": [
    "transformer_list, transformer_info_list = load_transformers_from_file(ioxfm_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YntFPS-vGLKS",
    "outputId": "d7f256a5-0c53-4ad3-bb05-86e80ce27036"
   },
   "outputs": [],
   "source": [
    "#create new model that wraps the inner kraken model and includes PCA transforms from raw data\n",
    "net=KrakenAdapter(inner_model=inner_net,\n",
    "                  data_transformer_list=[transformer_list[conntype] for conntype in checkpoint_info['input_name_list']],\n",
    "                  linear_polynomial_order=0,\n",
    "                  eval_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzzwlkEjI-Wa",
    "outputId": "3ab32c42-c17a-48c1-da57-59173fac4bbc"
   },
   "outputs": [],
   "source": [
    "#load example data (10 validation subjects from HCP-YA)\n",
    "conndata_squaremats=loadmat('/home/jovyan/shared/krakencoder/exampledata_10subj_fs86_inputs.mat',\n",
    "                            simplify_cells=True)\n",
    "\n",
    "#skip internal header keys\n",
    "conntypes=[c for c in conndata_squaremats.keys() if not c.startswith(\"_\")]\n",
    "\n",
    "#input data are lists of [roi x roi] square matrices so convert those to [subj x edges]\n",
    "conndata={}\n",
    "conndata_triidx={} #store so we can restore square later\n",
    "for c in conntypes:\n",
    "  conndata[c]={'data': np.stack([square2tri(x) for x in conndata_squaremats[c]['data']])}\n",
    "  _, conndata_triidx[c]=square2tri(conndata_squaremats[c]['data'][0],return_indices=True)\n",
    "  print(\"conndata_squaremats['%s']['data']\" % (c),conndata_squaremats[c]['data'].shape, conndata_squaremats[c]['data'][0].shape)\n",
    "  print(\" -> conndata['%s']['data']\" % (c),conndata[c]['data'].shape)\n",
    "del conndata_squaremats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2QaFJHjJfBR",
    "outputId": "2bed7f00-9195-4d63-d1ac-da71f821c54d"
   },
   "outputs": [],
   "source": [
    "# compute SIMPLE domain adaptation transform: map mean(input subjects) to mean(training subjects) for each flavor\n",
    "# and transform each input data flavor to match training data mean\n",
    "#\n",
    "# It's not really needed for these data since they are from HCP-YA already, which the model was trained on.\n",
    "# That is why the model fits are all roughly \"y = 1.0*x + 0\". It is shown here for demonstration purposes only.\n",
    "adxfm_dict={}\n",
    "conndata_adapted={}\n",
    "for c in conndata:\n",
    "  adxfm_dict[c]=generate_adapt_transformer(input_data=conndata[c]['data'],\n",
    "                                           target_data=transformer_info_list[c],\n",
    "                                           adapt_mode='meanfit+meanshift')\n",
    "  conndata_adapted[c]={'data':adxfm_dict[c].transform(conndata[c]['data'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xvojiqeAPJf",
    "outputId": "839460fb-80ed-43a1-a2aa-6ea7b2f3efeb"
   },
   "outputs": [],
   "source": [
    "# transform input data to krakencoder latent space\n",
    "encoded_data={}\n",
    "\n",
    "#loop through all of the input names from the saved checkpoint,\n",
    "# because the encoder/decoder indices are in this order.\n",
    "for encidx, c in enumerate(checkpoint_info['input_name_list']):\n",
    "  if not c in conndata_adapted:\n",
    "    #if this input type was not in the example data, skip it\n",
    "    continue\n",
    "  with torch.no_grad():\n",
    "    encoded_data[c]=net(conndata_adapted[c]['data'],encoder_index=encidx, decoder_index=-1)\n",
    "\n",
    "# compute average latent representation\n",
    "encoded_fusion=torch.mean(torch.stack([encoded_data[c] for c in encoded_data]),axis=0)\n",
    "\n",
    "print(\"fusion latent space representation: \", encoded_fusion.shape)\n",
    "\n",
    "# Now predict output connectomes from fusion latent representation\n",
    "# Predictions are stored in predicted_alltypes[inputtype][outputtype]\n",
    "predicted_alltypes={'fusion':{}}\n",
    "\n",
    "for decidx, c in enumerate(checkpoint_info['input_name_list']):\n",
    "  with torch.no_grad():\n",
    "    _,pred=net(encoded_fusion,encoder_index=-1, decoder_index=decidx)\n",
    "  predicted_alltypes['fusion'][c]=numpyvar(pred) #convert back to numpy for analysis\n",
    "  print(\"predicted_alltypes['fusion']['%s']: \" % (c), predicted_alltypes['fusion'][c].shape)\n",
    "\n",
    "#add fusion latent representation to output\n",
    "predicted_alltypes['fusion']['encoded']=numpyvar(encoded_fusion)\n",
    "print(\"predicted_alltypes['fusion']['%s']: \" % ('encoded'), predicted_alltypes['fusion']['encoded'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3aArUikSMfLc",
    "outputId": "3564fa7f-cc08-4b65-c886-c72319cf177b"
   },
   "outputs": [],
   "source": [
    "# save outputs to file for later analysis\n",
    "outfile='exampledata_outputs.mat'\n",
    "savemat(outfile, {'predicted_alltypes':predicted_alltypes}, format='5', do_compression=True)\n",
    "print(\"Saved %s (%s)\" % (outfile, humanize.naturalsize(os.path.getsize(outfile))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "f0iKl5MuL55k",
    "outputId": "bfa04747-1155-4756-9dd2-e72c3931f312"
   },
   "outputs": [],
   "source": [
    "# convert upper tri back to square to display observed and predicted connectomes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conntype='FCcorr_fs86_hpf'\n",
    "isubj=0\n",
    "\n",
    "Cobs_square=tri2square(conndata_adapted[conntype]['data'][isubj,:],\n",
    "                            tri_indices=conndata_triidx[conntype],\n",
    "                            diagval=1) #diagval=1 for FC\n",
    "Cpred_square=tri2square(predicted_alltypes['fusion'][conntype][isubj,:],\n",
    "                            tri_indices=conndata_triidx[conntype],\n",
    "                            diagval=1) #diagval=1 for FC\n",
    "\n",
    "#make sure these are converted back to CPU/numpy before trying to display\n",
    "Cobs_square=numpyvar(Cobs_square)\n",
    "Cpred_square=numpyvar(Cpred_square)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "im=plt.imshow(Cobs_square, vmin=-1, vmax=1, cmap='Spectral_r')\n",
    "plt.colorbar(im,fraction=0.046, pad=.04)\n",
    "plt.title('Obs. %s: Subj %d' % (conntype,isubj))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "im=plt.imshow(Cpred_square, vmin=-1, vmax=1, cmap='Spectral_r')\n",
    "plt.colorbar(im,fraction=0.046, pad=0.04)\n",
    "plt.title('Pred. %s: Subj %d' % (conntype,isubj))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP2rsMQ+r32uVUw4FJi3NGX",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
